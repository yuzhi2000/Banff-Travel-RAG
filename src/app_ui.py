import streamlit as st
import os
from dotenv import load_dotenv
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_core.output_parsers import StrOutputParser

# 1. è¨­å®šç¶²é æ¨™é¡Œèˆ‡é…ç½®
st.set_page_config(page_title="Banff ç­å¤«æ™ºæ…§æ—…éŠåŠ©æ‰‹", layout="wide")
st.title("ğŸ”ï¸ Banff National Park AI Guide")
st.caption("åŸºæ–¼ RAG æŠ€è¡“ (Gemini + ChromaDB + Multilingual Embedding)")

# 2. è¼‰å…¥ç’°å¢ƒè®Šæ•¸èˆ‡å¿«å–è³‡æº
load_dotenv()
DB_PATH = "./db/chroma_db"

# ä½¿ç”¨ @st.cache_resource é¿å…æ¯æ¬¡ç¶²é é‡æ•´éƒ½é‡æ–°è¼‰å…¥æ¨¡å‹ (é€™å¾ˆé‡è¦ï¼)
@st.cache_resource
def get_rag_chain():
    # A. æº–å‚™ Embedding
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    
    # B. è¼‰å…¥å‘é‡è³‡æ–™åº«
    vector_store = Chroma(
        persist_directory=DB_PATH,
        embedding_function=embeddings
    )
    # k=5 ç¢ºä¿èƒ½æŠ“åˆ°è£œå…¨çš„è¦å‰‡
    retriever = vector_store.as_retriever(search_kwargs={"k": 5})

    # C. æº–å‚™ LLM
    llm = ChatGoogleGenerativeAI(model="gemini-3-flash-preview", temperature=0)

    # D. Prompt Template
    template = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç­å¤«åœ‹å®¶å…¬åœ’æ—…éŠåš®å°ã€‚
    
    è«‹éµå¾ªä»¥ä¸‹å›ç­”é‚è¼¯ï¼š
    1. **å„ªå…ˆä½¿ç”¨ Context**ï¼šå¦‚æœä¸‹æ–¹çš„ Context åŒ…å«å›ç­”å•é¡Œæ‰€éœ€çš„è³‡è¨Šï¼Œè«‹ç›´æ¥å¼•ç”¨ Context å›ç­”ï¼Œä¸¦ç›¡é‡è©³ç´°ã€‚
    2. **è‡ªæœ‰çŸ¥è­˜å…œåº•**ï¼šå¦‚æœ Context è£¡ **å®Œå…¨æ²’æœ‰** ç›¸é—œè³‡è¨Šï¼Œè«‹ä½¿ç”¨ä½ ä½œç‚ºå¤§å‹èªè¨€æ¨¡å‹çš„è‡ªæœ‰çŸ¥è­˜ä¾†å›ç­”ã€‚
    
    âš ï¸ **é‡è¦é™åˆ¶**ï¼š
    - å¦‚æœä½ ä½¿ç”¨äº†è‡ªæœ‰çŸ¥è­˜ï¼ˆé Context å…§å®¹ï¼‰ï¼Œè«‹åœ¨å›ç­”çš„é–‹é ­åŠ ä¸Šæ¨™è¨»ï¼š**ã€Œ(æ³¨æ„ï¼šä»¥ä¸‹è³‡è¨Šä¾†è‡ª AI è³‡æ–™åº«ï¼Œéæœ¬æ¬¡æª¢ç´¢çµæœï¼Œåƒ…ä¾›åƒè€ƒ)ã€**ã€‚
    - å¦‚æœæ˜¯é—œæ–¼å…·é«”æ•¸æ“šï¼ˆå¦‚ç¥¨åƒ¹ã€é–‹æ”¾æ™‚é–“ï¼‰ä¸” Context æ²’æœ‰ï¼Œè«‹èª å¯¦èªªä¸çŸ¥é“ï¼Œä¸è¦çæ°æ•¸å­—ã€‚

    Context:
    {context}

    Question:
    {question}

    Answer:"""
    
    prompt = ChatPromptTemplate.from_template(template)

    # E. æ§‹å»º Chain (ä½¿ç”¨ RunnableParallel ä¾†åŒæ™‚å›å‚³ç­”æ¡ˆèˆ‡ä¾†æº)
    # é€™è£¡çš„æŠ€å·§æ˜¯ï¼šæˆ‘å€‘å…ˆä¸¦è¡Œå–å¾— context å’Œ questionï¼Œ
    # ç„¶å¾ŒæŠŠé€™å…©å€‹ä¸Ÿçµ¦ prompt -> llm -> parser ç”¢ç”Ÿ answerï¼Œ
    # æœ€å¾Œæˆ‘å€‘æœƒå¾—åˆ°ä¸€å€‹å­—å…¸ï¼š{'context': [...], 'question': '...', 'answer': '...'}
    chain = (
        RunnableParallel({"context": retriever, "question": RunnablePassthrough()})
        .assign(answer=prompt | llm | StrOutputParser())
    )
    
    return chain

# åˆå§‹åŒ– Chain
rag_chain = get_rag_chain()

# 3. è™•ç† Chat History (Session State)
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ä½ å¥½ï¼æˆ‘æ˜¯ç­å¤«æ—…éŠåŠ©æ‰‹ï¼Œæœ‰ä»€éº¼é—œæ–¼è¡Œç¨‹ã€äº¤é€šæˆ–ç¾é£Ÿçš„å•é¡Œéƒ½å¯ä»¥å•æˆ‘å–”ï¼"}]

# é¡¯ç¤ºéå»çš„å°è©±ç´€éŒ„
for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 4. è™•ç†ä½¿ç”¨è€…è¼¸å…¥
if user_query := st.chat_input("è«‹è¼¸å…¥ä½ çš„å•é¡Œ... (ä¾‹å¦‚ï¼šå¤¢è“®æ¹–å¯ä»¥é–‹è»Šå»å—ï¼Ÿ)"):
    # é¡¯ç¤ºä½¿ç”¨è€…å•é¡Œ
    st.session_state.messages.append({"role": "user", "content": user_query})
    st.chat_message("user").write(user_query)

    # AI æ€è€ƒèˆ‡ç”Ÿæˆ
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨æª¢ç´¢æ—…éŠæŒ‡å—..."):
            # å‘¼å« RAG Chain
            result = rag_chain.invoke(user_query)
            answer = result['answer']
            source_docs = result['context']

            # é¡¯ç¤ºå›ç­”
            st.write(answer)
            
            # æ›´æ–°å°è©±ç´€éŒ„
            st.session_state.messages.append({"role": "assistant", "content": answer})

            # --- é—œéµåŠŸèƒ½ï¼šåœ¨å´é‚Šæ¬„é¡¯ç¤ºå¼•ç”¨ä¾†æº (Source Citation) ---
            with st.sidebar:
                st.header("ğŸ“š æª¢ç´¢åˆ°çš„åƒè€ƒè³‡æ–™")
                st.write(f"é‡å°å•é¡Œï¼š**{user_query}**")
                st.divider()
                for i, doc in enumerate(source_docs):
                    with st.expander(f"ä¾†æºç‰‡æ®µ #{i+1}"):
                        st.markdown(f"**å…§å®¹æ‘˜è¦:** {doc.page_content}")
                        st.caption(f"Metadata: {doc.metadata}")
